{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote technique to optimize imbalanced data set\n",
    "\n",
    "· Baseline classification model – logistic regression & K-nearest\n",
    "\n",
    "· XG-Boost model – tune parameters via grid search\n",
    "\n",
    "· Lean into imbalance data set thing and anomaly detection\n",
    "\n",
    "Anomaly detection ideas:\n",
    "\n",
    "- Auto encoder\n",
    "- DB scan\n",
    "\n",
    "\n",
    "· Maybe correlate time feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opendatasets\n",
    "\n",
    "import opendatasets as od\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# %matplotlib\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data \n",
    "\n",
    "- retreived from kaggle portal\n",
    "- File too large to store in github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./creditcardfraud\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "dataset_url=\"https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/data\"\n",
    "\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['creditcard.csv']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"creditcardfraud\"\n",
    "\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n",
       "1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n",
       "2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n",
       "3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n",
       "4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n",
       "1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n",
       "2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n",
       "3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n",
       "4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
       "1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
       "2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
       "3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
       "4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
       "\n",
       "   Amount  Class  \n",
       "0  149.62      0  \n",
       "1    2.69      0  \n",
       "2  378.66      0  \n",
       "3  123.50      0  \n",
       "4   69.99      0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creditcard=data_dir + \"/creditcard.csv\"\n",
    "data = pd.read_csv(creditcard)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop = 492/ 284315\n",
    "round(prop, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#data imbalance\n",
    "sns.histplot(data['Class'])\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    25102462.04\n",
       "1       60127.97\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Class')['Amount'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in our case we may want to have detecting fraud as TP for confusion Matrix, this will allow that to happen\n",
    "# data[\"Class\"] = data[\"Class\"].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix Overview\n",
    "\n",
    "TP  FP \n",
    "\n",
    "FN  TN\n",
    "\n",
    "*TP:* Transaction is truly fraud\n",
    "\n",
    "*FP:* Transcation flagged as fraud when it actually wasn't\n",
    "\n",
    "*TN:* Transaction was not flagged for fraud and it is not a fradulent transaction\n",
    "\n",
    "*FN:* Transaction was not flagged for fraud but it is fraulent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(y_test, mod):\n",
    "    # Evaluate performance using classification report\n",
    "    print(classification_report(y_test, mod))\n",
    "\n",
    "    # Evaluate performance using confusion matrix\n",
    "    print(confusion_matrix(y_test, mod))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base model\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters**\n",
    "\n",
    "solver: {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "\n",
    "- lbfgs: relatively good perform (may have issues with convergence)\n",
    "- sag: faster than other for large datasets, when both the number of samples and the number of features are large\n",
    "- saga: sparse multinomial logistic regression and suitable for very large datasets\n",
    "- newton-cg: computationally expensive because of the Hessian Matrix\n",
    "- liblinear: recommended for high dimension dataset - solving large-scale classification problems\n",
    "\n",
    "penalty: {‘l1’, ‘l2’, ‘elasticnet’, None}, default=’l2’\n",
    "\n",
    "tol: tolerance to stopping (early stopping)\n",
    "\n",
    "C: regularization strength\n",
    "\n",
    "dual:\n",
    "\n",
    "fit_intercept:\n",
    "\n",
    "intercept_scaling:\n",
    "\n",
    "class_weight: \n",
    "\n",
    "max_iter:\n",
    "\n",
    "verbose:\n",
    "\n",
    "warm_start:\n",
    "\n",
    "n_jobs:\n",
    "\n",
    "l1_ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.83      0.53      0.65        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.77      0.82     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56853    11]\n",
      " [   46    52]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True:    284315\n",
    "\n",
    "Fraudulent:       492"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "XGBoost: Extreme Gradient Boost is distributed-boosted gradient tree. \n",
    "\n",
    "- improves a single weak model by combining it with a number of other weak models to generate a collectively strong model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**xgb.train():**\n",
    "- lower-level function in XGBoost that allows you to train a gradient boosting model with fine-grained control over parameters\n",
    "- It requires you to explicitly define the model parameters\n",
    "- Need to prepare the data beforehand and pass it to the function as DMatrix objects\n",
    "\n",
    "\n",
    "- Pro: More flexibility and customization optionss\n",
    "- Con: ore manual intervention and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9995435553526912\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'multi:softmax',  # Multiclass classification\n",
    "    'num_class': 5,                # Number of classes\n",
    "    'eta': 0.01,                   # Learning rate\n",
    "    'max_depth': 6,                # Maximum depth of a tree\n",
    "    'min_child_weight': 1,         # Minimum sum of instance weight required in a child\n",
    "    'subsample': 0.8,              # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.6,       # Subsample ratio of columns when constructing each tree\n",
    "    'gamma': 0.3,                  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'lambda': 0.6,                 # L2 regularization term on weights\n",
    "    'alpha': 0.2,                  # L1 regularization term on weights\n",
    "    'scale_pos_weight': 0.4,       # Control the balance of positive and negative weights\n",
    "    'tree_method': 'auto',       # Tree construction algorithm\n",
    "    'grow_policy': 'lossguide'  \n",
    "}\n",
    "\n",
    "# Convert data into DMatrix format\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Train the XGBoost model\n",
    "epochs = 100\n",
    "bst = xgb.train(params, dtrain, epochs)\n",
    "\n",
    "# Predictions\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.74      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.87      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56863     1]\n",
      " [   25    73]]\n"
     ]
    }
   ],
   "source": [
    "report(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBClassifier():**\n",
    "- Higher-level interface for classification tasks\n",
    "- Follows the same API conventions as other classifiers in scikit-learn, (easier to use within scikit-learn pipelines and workflows)\n",
    "- Handles many details internally (data preprocessing, model initialization, and parameter tuning) \n",
    "- You can directly pass the raw data (features and labels) to XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.78      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56861     3]\n",
      " [   22    76]]\n"
     ]
    }
   ],
   "source": [
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Test Accuracy with Best Hyperparameters: 0.9995962220427653\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator= model, param_grid= param_grid, cv= 3, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Test Accuracy with Best Hyperparameters:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE(*, \n",
    "\n",
    "*sampling_strategy*= float (only for binary), str (in our casue will use either auto or minority), dict or callable, default=’auto’,  \n",
    "\n",
    "*random_state*= controls randomization, \n",
    "\n",
    "*k_neighbors*= define the neighborhood of samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 227451, 1: 227451})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in terminal: conda install -c conda-forge imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_resampled)\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56864\n",
      "           1       0.10      0.89      0.18        98\n",
      "\n",
      "    accuracy                           0.99     56962\n",
      "   macro avg       0.55      0.94      0.59     56962\n",
      "weighted avg       1.00      0.99      0.99     56962\n",
      "\n",
      "[[56083   781]\n",
      " [   11    87]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE on XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.80      0.86      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.93      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56843    21]\n",
      " [   14    84]]\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Play Around With SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.82      0.83      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56846    18]\n",
      " [   17    81]]\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors= 7)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_resampled)\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boarderline SMOTE\n",
    "\n",
    "Similar to ADASYN, looks at minority points that are on the boarder (and creates an imaginay line) with the majority points and creates more minority points along the imaginary lines\n",
    "\n",
    "\n",
    "BoarderlineSMOTE(*, \n",
    "\n",
    "sampling_strategy= float, str, dict or callable, default=’auto’, \n",
    "\n",
    "random_state= Control the randomization , \n",
    "\n",
    "k_neighbors= used to define the neighborhood of samples, \n",
    "\n",
    "m_neighbors= The nearest neighbors used to determine if a minority sample is in “danger”., \n",
    "\n",
    "kind='borderline-1' or 'borderline-2')\n",
    "- boarderline-1: oversampling along border for both classes\n",
    "- boarderline-2: oversampling along boarder for **minority class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.99      0.80      0.88        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.99      0.90      0.94     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56863     1]\n",
      " [   20    78]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "smote = BorderlineSMOTE(random_state=42, kind= 'borderline-2')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_resampled)\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.94      0.81      0.87        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.90      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56859     5]\n",
      " [   19    79]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "smote = BorderlineSMOTE(random_state=42, k_neighbors= 7, m_neighbors= 5, kind= 'borderline-2')\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "counter = Counter(y_train_resampled)\n",
    "\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADASYN\n",
    "\n",
    "increases minority observations and placing more weights near observations that are more difficult to classify\n",
    "\n",
    "- if points are next to points of the different classification then ADASYN will ad more minority classification points in this area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.86      0.84      0.85        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.92      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56851    13]\n",
      " [   16    82]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42,  n_neighbors= 3) \n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.85      0.83        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.92      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56845    19]\n",
      " [   15    83]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "adasyn = ADASYN(random_state=42) \n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch after ADASYN oversampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200}\n",
      "Test Accuracy with Best Hyperparameters: 0.9993679997191109\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator= model, param_grid= param_grid, cv= 3, scoring='accuracy')\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "model = XGBClassifier(**best_params)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Test Accuracy with Best Hyperparameters:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
